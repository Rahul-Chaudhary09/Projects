{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNU0lgBIE0bdYYl7u8pQmEX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n","from sklearn.compose import ColumnTransformer\n","from sklearn.impute import SimpleImputer\n","from sklearn.pipeline import Pipeline # <--- MOVED THIS IMPORT HERE!\n","import warnings\n","\n","# Suppress harmless warnings for cleaner output\n","warnings.filterwarnings('ignore')\n","\n","print(\"--- Titanic Survival Predictor Project ---\")\n","print(\"1. Loading Data...\")\n","\n","# --- 1. Load Data ---\n","# Using the raw CSV directly from GitHub for easy 'readymade' use\n","try:\n","    url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n","    df = pd.read_csv(url)\n","    print(\"Data loaded successfully from URL.\")\n","except Exception as e:\n","    print(f\"Error loading data from URL: {e}\")\n","    print(\"Please ensure you have an internet connection or download 'titanic.csv' manually.\")\n","    print(\"Assuming 'titanic.csv' is in the same directory.\")\n","    try:\n","        df = pd.read_csv('titanic.csv')\n","        print(\"Data loaded successfully from local file.\")\n","    except FileNotFoundError:\n","        print(\"Error: 'titanic.csv' not found. Please place it in the same directory as the script.\")\n","        exit() # Exit if data can't be loaded\n","\n","# Display basic info\n","print(\"\\nDataset Head:\")\n","print(df.head())\n","print(\"\\nDataset Info:\")\n","df.info()\n","\n","print(\"\\n2. Preprocessing Data...\")\n","\n","# --- 2. Preprocessing Data ---\n","\n","# Define features (X) and target (y)\n","# Dropping 'PassengerId', 'Name', 'Ticket', 'Cabin' as they are not directly useful or have too many missing values\n","features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n","target = 'Survived'\n","\n","X = df[features]\n","y = df[target]\n","\n","# Separate features into numerical and categorical for different preprocessing steps\n","numerical_features = ['Age', 'Fare', 'SibSp', 'Parch']\n","categorical_features = ['Pclass', 'Sex', 'Embarked'] # Pclass treated as categorical for simplicity here\n","\n","# Create preprocessing pipelines for numerical and categorical features\n","# Impute missing numerical values with the median\n","numerical_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='median')),\n","    ('scaler', StandardScaler()) # Scale numerical features\n","])\n","\n","# Impute missing categorical values with the most frequent, then One-Hot Encode\n","categorical_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='most_frequent')),\n","    ('onehot', OneHotEncoder(handle_unknown='ignore')) # Convert categorical to one-hot vectors\n","])\n","\n","# Create a preprocessor using ColumnTransformer\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numerical_transformer, numerical_features),\n","        ('cat', categorical_transformer, categorical_features)\n","    ])\n","\n","# --- 3. Split Data ---\n","print(\"3. Splitting data into training and testing sets...\")\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # 80% train, 20% test\n","\n","print(f\"Training data shape: {X_train.shape}\")\n","print(f\"Testing data shape: {X_test.shape}\")\n","\n","print(\"\\n4. Training the Model...\")\n","\n","# --- 4. Create and Train the Model (with pipeline for preprocessing) ---\n","# from sklearn.pipeline import Pipeline # <--- This line was here previously, causing the error!\n","\n","model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n","                               ('classifier', LogisticRegression(random_state=42))]) # Use Logistic Regression\n","\n","# Train the model\n","model_pipeline.fit(X_train, y_train)\n","print(\"Model trained successfully using Logistic Regression.\")\n","\n","print(\"\\n5. Evaluating the Model...\")\n","\n","# --- 5. Evaluate the Model ---\n","y_pred = model_pipeline.predict(X_test)\n","\n","accuracy = accuracy_score(y_test, y_pred)\n","report = classification_report(y_test, y_pred)\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","\n","print(f\"Accuracy: {accuracy:.2f}\")\n","print(\"\\nClassification Report:\")\n","print(report)\n","print(\"\\nConfusion Matrix:\")\n","print(conf_matrix)\n","print(\"  (True Negative  False Positive)\")\n","print(\"  (False Negative True Positive )\")\n","\n","\n","print(\"\\n--- Project Complete ---\")\n","print(\"This simple model demonstrates data loading, preprocessing, training, and evaluation.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jLTV_4rDSdnz","executionInfo":{"status":"ok","timestamp":1752401834689,"user_tz":-330,"elapsed":498,"user":{"displayName":"Rahul Chaudhary","userId":"02416593744586583657"}},"outputId":"24f4691d-6b8a-4a49-f45b-99d3c7421f78"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Titanic Survival Predictor Project ---\n","1. Loading Data...\n","Data loaded successfully from URL.\n","\n","Dataset Head:\n","   PassengerId  Survived  Pclass  \\\n","0            1         0       3   \n","1            2         1       1   \n","2            3         1       3   \n","3            4         1       1   \n","4            5         0       3   \n","\n","                                                Name     Sex   Age  SibSp  \\\n","0                            Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                             Heikkinen, Miss. Laina  female  26.0      0   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                           Allen, Mr. William Henry    male  35.0      0   \n","\n","   Parch            Ticket     Fare Cabin Embarked  \n","0      0         A/5 21171   7.2500   NaN        S  \n","1      0          PC 17599  71.2833   C85        C  \n","2      0  STON/O2. 3101282   7.9250   NaN        S  \n","3      0            113803  53.1000  C123        S  \n","4      0            373450   8.0500   NaN        S  \n","\n","Dataset Info:\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 891 entries, 0 to 890\n","Data columns (total 12 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   PassengerId  891 non-null    int64  \n"," 1   Survived     891 non-null    int64  \n"," 2   Pclass       891 non-null    int64  \n"," 3   Name         891 non-null    object \n"," 4   Sex          891 non-null    object \n"," 5   Age          714 non-null    float64\n"," 6   SibSp        891 non-null    int64  \n"," 7   Parch        891 non-null    int64  \n"," 8   Ticket       891 non-null    object \n"," 9   Fare         891 non-null    float64\n"," 10  Cabin        204 non-null    object \n"," 11  Embarked     889 non-null    object \n","dtypes: float64(2), int64(5), object(5)\n","memory usage: 83.7+ KB\n","\n","2. Preprocessing Data...\n","3. Splitting data into training and testing sets...\n","Training data shape: (712, 7)\n","Testing data shape: (179, 7)\n","\n","4. Training the Model...\n","Model trained successfully using Logistic Regression.\n","\n","5. Evaluating the Model...\n","Accuracy: 0.80\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.81      0.86      0.83       105\n","           1       0.78      0.72      0.75        74\n","\n","    accuracy                           0.80       179\n","   macro avg       0.80      0.79      0.79       179\n","weighted avg       0.80      0.80      0.80       179\n","\n","\n","Confusion Matrix:\n","[[90 15]\n"," [21 53]]\n","  (True Negative  False Positive)\n","  (False Negative True Positive )\n","\n","--- Project Complete ---\n","This simple model demonstrates data loading, preprocessing, training, and evaluation.\n","You can experiment with other models (e.g., RandomForestClassifier) or more feature engineering!\n"]}]}]}